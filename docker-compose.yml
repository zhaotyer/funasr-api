services:
  nginx:
    image: nginx:1.27-alpine
    container_name: funasr-nginx
    ports:
      - "17003:80"
    volumes:
      - ./funasr.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - funasr-api
    restart: unless-stopped
    networks:
      - funasr-net

  # 单节点：用线程池实现并发与排队（适合离线长音频）
  funasr-api:
    image: quantatrisk/funasr-api:gpu-latest
    container_name: funasr-api
    gpus:
      - driver: nvidia
        device_ids: ["0"]
        capabilities: [gpu]
    expose:
      - "8000"
    volumes:
      - ./temp:/app/temp
      - ./data:/app/data
      - ./logs:/app/logs
    env_file:
      - .env
    environment:
      - DEBUG=false
      - LOG_LEVEL=INFO
      - HOST=0.0.0.0
      - PORT=8000
      - DEVICE=cuda:0
      - NVIDIA_VISIBLE_DEVICES=0
      - CUDA_VISIBLE_DEVICES=0
      # 多进程会复制模型、显存成倍增加；离线长音频建议保持 1
      - WORKERS=1
      # 推理线程池大小决定“同时跑推理的数量”，其余请求会在队列中等待
      # 建议从 2~4 开始逐步调参
      - INFERENCE_THREAD_POOL_SIZE=4
    restart: unless-stopped
    networks:
      - funasr-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]

networks:
  funasr-net:
    name: funasr-net
